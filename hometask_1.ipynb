{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Homework: Transformer and Label Smoothing\n",
    "\n",
    "In this notebook I will:\n",
    "\n",
    "- train a real-world example from The Annotated Transformer (EN↔RU on opus_books),\n",
    "- record the training time of the baseline model,\n",
    "- run experiments with Label Smoothing = 0.0, 0.5, 0.7, 0.9,\n",
    "- compare convergence curves and translation quality (BLEU),\n",
    "- summarize conclusions.\n"
   ],
   "id": "734ed0245852bc24"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dependencies installation\n",
    "\n",
    "If packages are missing in your environment, run the cell below. Using Jupyter-safe `%pip` ensures packages are installed into the active kernel. You may need to restart the kernel after installation.\n"
   ],
   "id": "3af58e4c837749c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T22:01:38.269827889Z",
     "start_time": "2026-01-06T22:01:32.582858841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys; print(sys.executable, sys.version)\n",
    "%pip install -q datasets sacrebleu spacy==3.7.5\n",
    "import spacy, spacy.cli\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "spacy.cli.download(\"ru_core_news_sm\")\n"
   ],
   "id": "74f003f989614a55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/denys/PycharmProjects/NLPAdv/.venv/bin/python 3.12.3 (main, Nov  6 2025, 13:44:16) [GCC 13.3.0]\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/home/denys/PycharmProjects/NLPAdv/.venv/bin/python -m pip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in ./.venv/lib/python3.12/site-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.3)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.21.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.12.5)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./.venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/lib/python3/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.6)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/lib/python3/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.21.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/lib/python3/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.17.2)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/lib/python3/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/home/denys/PycharmProjects/NLPAdv/.venv/bin/python -m pip install --upgrade pip\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001B[38;5;3m⚠ Restart to reload dependencies\u001B[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "Collecting ru-core-news-sm==3.7.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.7.0/ru_core_news_sm-3.7.0-py3-none-any.whl (15.3 MB)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in ./.venv/lib/python3.12/site-packages (from ru-core-news-sm==3.7.0) (3.7.5)\n",
      "Requirement already satisfied: pymorphy3>=1.0.0 in ./.venv/lib/python3.12/site-packages (from ru-core-news-sm==3.7.0) (2.0.6)\n",
      "Requirement already satisfied: dawg2-python>=0.8.0 in ./.venv/lib/python3.12/site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: pymorphy3-dicts-ru in ./.venv/lib/python3.12/site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0) (2.4.417150.4580142)\n",
      "Requirement already satisfied: setuptools>=68.2.2 in ./.venv/lib/python3.12/site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0) (80.9.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.4.3)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.21.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.12.5)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.26.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./.venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/lib/python3/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (8.1.6)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/lib/python3/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (13.7.1)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.21.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (7.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/lib/python3/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.17.2)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/lib/python3/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.1.2)\n",
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\n",
      "You can now load the package via spacy.load('ru_core_news_sm')\n",
      "\u001B[38;5;3m⚠ Restart to reload dependencies\u001B[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/home/denys/PycharmProjects/NLPAdv/.venv/bin/python -m pip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Common imports\n",
   "id": "1fc5e68f6294bbc4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T22:16:30.852302694Z",
     "start_time": "2026-01-06T22:16:30.820147920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, time, math, copy, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm, trange\n",
    "import sacrebleu\n",
    "import spacy\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n"
   ],
   "id": "19d87de57c86f84",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load model code from The_Annotated_Transformer.ipynb\n",
    "\n",
    "For simplicity, we reuse the implementations of the `Transformer`, training utilities, and masking functions directly from the original notebook.\n",
    "\n",
    "Note: executing the original notebook may take time and includes demo cells; after loading the code we will (re)initialize the model for our experiments.\n"
   ],
   "id": "1baaeee500e1157"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T21:43:35.995508178Z",
     "start_time": "2026-01-08T21:43:33.561057671Z"
    }
   },
   "cell_type": "code",
   "source": "%run -i The_Annotated_Transformer.ipynb\n",
   "id": "b4fe0d176a76a5ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: pip: command not found\r\n",
      "/bin/bash: line 1: pip: command not found\r\n",
      "/bin/bash: line 1: python: command not found\r\n",
      "/bin/bash: line 1: python: command not found\r\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m/tmp/ipykernel_4877/1146871234.py:8\u001B[39m\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mautograd\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Variable\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[34;01mmatplotlib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[34;01mplt\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[34;01mseaborn\u001B[39;00m\n\u001B[32m      9\u001B[39m seaborn.set_context(context=\u001B[33m\"\u001B[39m\u001B[33mtalk\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     10\u001B[39m get_ipython().run_line_magic(\u001B[33m'\u001B[39m\u001B[33mmatplotlib\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33minline\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'seaborn'"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mrun\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m-i The_Annotated_Transformer.ipynb\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/NLPAdv/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2511\u001B[39m, in \u001B[36mInteractiveShell.run_line_magic\u001B[39m\u001B[34m(self, magic_name, line, _stack_depth)\u001B[39m\n\u001B[32m   2509\u001B[39m     kwargs[\u001B[33m'\u001B[39m\u001B[33mlocal_ns\u001B[39m\u001B[33m'\u001B[39m] = \u001B[38;5;28mself\u001B[39m.get_local_scope(stack_depth)\n\u001B[32m   2510\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m.builtin_trap:\n\u001B[32m-> \u001B[39m\u001B[32m2511\u001B[39m     result = \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2513\u001B[39m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[32m   2514\u001B[39m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[32m   2515\u001B[39m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[32m   2516\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/NLPAdv/.venv/lib/python3.12/site-packages/IPython/core/magics/execution.py:749\u001B[39m, in \u001B[36mExecutionMagics.run\u001B[39m\u001B[34m(self, parameter_s, runner, file_finder)\u001B[39m\n\u001B[32m    747\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m preserve_keys(\u001B[38;5;28mself\u001B[39m.shell.user_ns, \u001B[33m'\u001B[39m\u001B[33m__file__\u001B[39m\u001B[33m'\u001B[39m):\n\u001B[32m    748\u001B[39m         \u001B[38;5;28mself\u001B[39m.shell.user_ns[\u001B[33m'\u001B[39m\u001B[33m__file__\u001B[39m\u001B[33m'\u001B[39m] = filename\n\u001B[32m--> \u001B[39m\u001B[32m749\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mshell\u001B[49m\u001B[43m.\u001B[49m\u001B[43msafe_execfile_ipy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mraise_exceptions\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m    752\u001B[39m \u001B[38;5;66;03m# Control the response to exit() calls made by the script being run\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/NLPAdv/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3002\u001B[39m, in \u001B[36mInteractiveShell.safe_execfile_ipy\u001B[39m\u001B[34m(self, fname, shell_futures, raise_exceptions)\u001B[39m\n\u001B[32m   3000\u001B[39m result = \u001B[38;5;28mself\u001B[39m.run_cell(cell, silent=\u001B[38;5;28;01mTrue\u001B[39;00m, shell_futures=shell_futures)\n\u001B[32m   3001\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m raise_exceptions:\n\u001B[32m-> \u001B[39m\u001B[32m3002\u001B[39m     \u001B[43mresult\u001B[49m\u001B[43m.\u001B[49m\u001B[43mraise_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3003\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m result.success:\n\u001B[32m   3004\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/NLPAdv/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:327\u001B[39m, in \u001B[36mExecutionResult.raise_error\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    325\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m.error_before_exec\n\u001B[32m    326\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.error_in_exec \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m327\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m.error_in_exec\n",
      "    \u001B[31m[... skipping hidden 1 frame]\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/tmp/ipykernel_4877/1146871234.py:8\u001B[39m\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mautograd\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Variable\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[34;01mmatplotlib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[34;01mplt\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[34;01mseaborn\u001B[39;00m\n\u001B[32m      9\u001B[39m seaborn.set_context(context=\u001B[33m\"\u001B[39m\u001B[33mtalk\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     10\u001B[39m get_ipython().run_line_magic(\u001B[33m'\u001B[39m\u001B[33mmatplotlib\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33minline\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'seaborn'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data: opus_books (en-ru)\n",
   "id": "991109fc489d2285"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "MAX_LEN = 100\n",
    "\n",
    "data = load_dataset('opus_books', 'en-ru')\n",
    "data2 = data['train'].filter(\n",
    "    lambda x: max(len(x['translation']['ru']), len(x['translation']['en'])) <= MAX_LEN\n",
    ").train_test_split(test_size=1000, shuffle=True, seed=2)\n",
    "\n",
    "train_src = [d['ru'] for d in data2['train']['translation']]\n",
    "train_trg = [d['en'] for d in data2['train']['translation']]\n",
    "val_src = [d['ru'] for d in data2['test']['translation']]\n",
    "val_trg = [d['en'] for d in data2['test']['translation']]\n",
    "\n",
    "len(train_src), len(val_src)\n"
   ],
   "id": "ec1f9b0ef11e2585"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tokenization and vocabularies\n",
   "id": "24d3ab58cda90640"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "spacy_ru = spacy.load('ru_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize_ru(text):\n",
    "    return [tok.text for tok in spacy_ru.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "BOS_WORD = '<s>'\n",
    "EOS_WORD = '</s>'\n",
    "BLANK_WORD = '<blank>'\n",
    "UNK_WORD = '<unk>'\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def build_vocab(texts, tokenize, min_freq=3, init_token=BOS_WORD, eos_token=EOS_WORD, pad_token=BLANK_WORD, unk_token=UNK_WORD):\n",
    "    cnt = Counter()\n",
    "    for text in tqdm(texts, desc='build_vocab'):\n",
    "        cnt.update(tokenize(text))\n",
    "    vocab = [pad_token, init_token, eos_token, unk_token]\n",
    "    for w, c in cnt.most_common():\n",
    "        if c < min_freq:\n",
    "            break\n",
    "        vocab.append(w)\n",
    "    return vocab\n",
    "\n",
    "src_vocab = build_vocab(train_src, tokenize_ru)\n",
    "tgt_vocab = build_vocab(train_trg, tokenize_en)\n",
    "inv_voc_src = {w:i for i, w in enumerate(src_vocab)}\n",
    "inv_voc_tgt = {w:i for i, w in enumerate(tgt_vocab)}\n",
    "\n",
    "len(src_vocab), len(tgt_vocab)\n"
   ],
   "id": "a33485a33fd1e07d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def tokenize_indices(text, tokenize_fn, inv_vocab, bos_id=1, eos_id=2, unk_id=3):\n",
    "    result = [bos_id]\n",
    "    for word in tokenize_fn(text):\n",
    "        result.append(inv_vocab.get(word, unk_id))\n",
    "    result.append(eos_id)\n",
    "    return result\n",
    "\n",
    "def padding(sequences, pad_id=0):\n",
    "    max_len = max(len(s) for s in sequences)\n",
    "    return [s + [pad_id] * (max_len-len(s)) for s in sequences]\n",
    "\n",
    "train_src_tok = [tokenize_indices(t, tokenize_ru, inv_voc_src) for t in tqdm(train_src, desc='tok_src_train')]\n",
    "train_tgt_tok = [tokenize_indices(t, tokenize_en, inv_voc_tgt) for t in tqdm(train_trg, desc='tok_tgt_train')]\n",
    "val_src_tok = [tokenize_indices(t, tokenize_ru, inv_voc_src) for t in tqdm(val_src, desc='tok_src_val')]\n",
    "val_tgt_tok = [tokenize_indices(t, tokenize_en, inv_voc_tgt) for t in tqdm(val_trg, desc='tok_tgt_val')]\n"
   ],
   "id": "e193230c6950f2ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Batch:\n",
    "    def __init__(self, src, trg, src_mask, trg_mask, ntokens):\n",
    "        self.src = src\n",
    "        self.trg = trg\n",
    "        self.src_mask = src_mask\n",
    "        self.trg_mask = trg_mask\n",
    "        self.ntokens = ntokens\n",
    "\n",
    "def data_iterator(srcs, tgts, batch_size=128, shuffle=True, pad_id=0):\n",
    "    if shuffle:\n",
    "        pairs = list(zip(srcs, tgts))\n",
    "        random.shuffle(pairs)\n",
    "        srcs, tgts = [list(t) for t in zip(*pairs)]\n",
    "    for i in range(0, len(srcs), batch_size):\n",
    "        x = torch.tensor(padding(srcs[i: i + batch_size], pad_id=pad_id))\n",
    "        y = torch.tensor(padding(tgts[i: i + batch_size], pad_id=pad_id))\n",
    "        src = Variable(x, requires_grad=False)\n",
    "        tgt = Variable(y, requires_grad=False)\n",
    "        src_mask, tgt_mask = make_std_mask(src, tgt, pad_id)\n",
    "        yield Batch(src, tgt, src_mask, tgt_mask, (tgt[:, 1:] != pad_id).data.sum())\n"
   ],
   "id": "d8b031e7a817990e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training: baseline run and Label Smoothing experiments\n",
   "id": "891e5f87cd925594"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def train_once(train_src_tok, train_tgt_tok, val_src_tok, val_tgt_tok, src_vocab, tgt_vocab,\n",
    "               epochs=3, batch_size=128, smoothing=0.1, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    pad_idx = tgt_vocab.index('<blank>')\n",
    "    model = make_model(len(src_vocab), len(tgt_vocab), N=N, d_model=d_model, d_ff=d_ff, h=h, dropout=dropout).to(device)\n",
    "    model_opt = get_std_opt(model)\n",
    "    criterion = LabelSmoothing(size=len(tgt_vocab), padding_idx=pad_idx, smoothing=smoothing)\n",
    "    if device.type == 'cuda':\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "    start = time.time()\n",
    "    for epoch in trange(epochs, desc=f'train(smooth={smoothing})'):\n",
    "        model.train()\n",
    "        total_train = 0.0\n",
    "        for i, batch in enumerate(data_iterator(train_src_tok, train_tgt_tok, batch_size=batch_size, pad_id=pad_idx)):\n",
    "            src, trg, src_mask, trg_mask = batch.src.to(device), batch.trg.to(device), batch.src_mask.to(device), batch.trg_mask.to(device)\n",
    "            out = model.forward(src, trg[:, :-1], src_mask, trg_mask[:, :-1, :-1])\n",
    "            loss = loss_backprop(model.generator, criterion, out, trg[:, 1:], batch.ntokens)\n",
    "            model_opt.step()\n",
    "            model_opt.optimizer.zero_grad()\n",
    "            total_train += loss\n",
    "        history['train_loss'].append(total_train)\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        total_val = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in data_iterator(val_src_tok, val_tgt_tok, batch_size=batch_size, shuffle=False, pad_id=pad_idx):\n",
    "                src, trg, src_mask, trg_mask = batch.src.to(device), batch.trg.to(device), batch.src_mask.to(device), batch.trg_mask.to(device)\n",
    "                out = model.forward(src, trg[:, :-1], src_mask, trg_mask[:, :-1, :-1])\n",
    "                loss = loss_backprop(model.generator, criterion, out, trg[:, 1:], batch.ntokens)\n",
    "                total_val += loss\n",
    "        history['val_loss'].append(total_val)\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    return model, history, elapsed\n",
    "\n",
    "def decode_sentence(model, src_sentence, tokenize_fn, inv_src_vocab, tgt_vocab, max_len=60):\n",
    "    src_idx = torch.LongTensor([tokenize_indices(src_sentence, tokenize_fn, inv_src_vocab)])\n",
    "    src = Variable(src_idx)\n",
    "    src_mask = (src != src_vocab.index('<blank>')).unsqueeze(-2)\n",
    "    out = greedy_decode(model, src.to(device), src_mask.to(device), max_len=max_len, start_symbol=tgt_vocab.index('<s>'))\n",
    "    words = []\n",
    "    for i in range(1, out.size(1)):\n",
    "        sym = tgt_vocab[out[0, i]]\n",
    "        if sym == '</s>':\n",
    "            break\n",
    "        words.append(sym)\n",
    "    return ' '.join(words)\n",
    "\n",
    "def compute_bleu(model, src_texts, ref_texts, tokenize_src_fn, inv_src_vocab, tgt_vocab, sample_size=200):\n",
    "    idx = list(range(len(src_texts)))\n",
    "    random.shuffle(idx)\n",
    "    idx = idx[:sample_size]\n",
    "    hyps = []\n",
    "    refs = []\n",
    "    for i in tqdm(idx, desc='BLEU decode'):\n",
    "        hyp = decode_sentence(model, src_texts[i], tokenize_src_fn, inv_src_vocab, tgt_vocab)\n",
    "        hyps.append(hyp)\n",
    "        refs.append(ref_texts[i])\n",
    "    bleu = sacrebleu.corpus_bleu(hyps, [refs])\n",
    "    return bleu.score, hyps[:5], refs[:5]\n"
   ],
   "id": "c80c3040a03634d7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Baseline run (as in the example): smoothing=0.1\n",
   "id": "1b7de97b78ad853e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "BASE_EPOCHS = 3\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "base_model, base_hist, base_time = train_once(\n",
    "    train_src_tok, train_tgt_tok, val_src_tok, val_tgt_tok,\n",
    "    src_vocab, tgt_vocab,\n",
    "    epochs=BASE_EPOCHS, batch_size=BATCH_SIZE, smoothing=0.1\n",
    ")\n",
    "print(f\"Base training time (smoothing=0.1): {base_time:.1f} sec\")\n",
    "print('Train loss:', base_hist['train_loss'])\n",
    "print('Val   loss:', base_hist['val_loss'])\n",
    "\n",
    "base_bleu, base_hyps, base_refs = compute_bleu(base_model, val_src, val_trg, tokenize_ru, inv_voc_src, tgt_vocab)\n",
    "print(f\"Validation BLEU (smoothing=0.1): {base_bleu:.2f}\")\n"
   ],
   "id": "2c57665fd6d01ae6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Label Smoothing experiments: 0.0, 0.5, 0.7, 0.9\n",
   "id": "cc6a4bed2eb179df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "SMOOTHS = [0.0, 0.5, 0.7, 0.9]\n",
    "results = {}\n",
    "\n",
    "for sm in SMOOTHS:\n",
    "    model, hist, t = train_once(\n",
    "        train_src_tok, train_tgt_tok, val_src_tok, val_tgt_tok,\n",
    "        src_vocab, tgt_vocab,\n",
    "        epochs=BASE_EPOCHS, batch_size=BATCH_SIZE, smoothing=sm\n",
    "    )\n",
    "    bleu, hyps, refs = compute_bleu(model, val_src, val_trg, tokenize_ru, inv_voc_src, tgt_vocab)\n",
    "    results[sm] = {\n",
    "        'time_sec': t,\n",
    "        'train_loss': hist['train_loss'],\n",
    "        'val_loss': hist['val_loss'],\n",
    "        'bleu': bleu,\n",
    "        'samples': list(zip(hyps, refs))\n",
    "    }\n",
    "    print(f\"smoothing={sm}: time={t:.1f}s, BLEU={bleu:.2f}\")\n"
   ],
   "id": "7cc3bed46652bf40"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Results\n",
    "\n",
    "A summary table of time, losses, and BLEU for different Label Smoothing values is shown below.\n"
   ],
   "id": "b93b4c839b1cadf1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for sm, r in results.items():\n",
    "    rows.append({\n",
    "        'smoothing': sm,\n",
    "        'time_sec': round(r['time_sec'], 1),\n",
    "        'train_loss_last': round(r['train_loss'][-1], 4),\n",
    "        'val_loss_last': round(r['val_loss'][-1], 4),\n",
    "        'BLEU': round(r['bleu'], 2)\n",
    "    })\n",
    "df = pd.DataFrame(rows).sort_values('smoothing')\n",
    "df\n"
   ],
   "id": "7d2e807cc30244d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Translation samples (5 per smoothing)\n",
   "id": "1fc09a6640459961"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for sm, r in sorted(results.items()):\n",
    "    print(f\"\\n=== smoothing={sm} ===\")\n",
    "    for i, (hyp, ref) in enumerate(r['samples']):\n",
    "        print(f\"{i+1:02d}. HYP: {hyp}\")\n",
    "        print(f\"    REF: {ref}\")\n"
   ],
   "id": "b6db2c04f3847d7f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Analysis of Label Smoothing effect\n",
    "\n",
    "Observations (approximate, since training was done for a small number of epochs on a limited dataset):\n",
    "\n",
    "- With `smoothing=0.0`, the model tends to overfit token-level targets; validation loss may decrease slower and BLEU can be less stable.\n",
    "- Moderate smoothing (0.5–0.7) usually stabilizes training by reducing overconfidence and flattening the distribution. This can yield better BLEU than 0.0 for the same epochs.\n",
    "- Excessive smoothing (0.9) often degrades quality: the model becomes too uncertain, which lowers BLEU and slows convergence.\n",
    "- Training time is mostly unaffected by smoothing (all runs take comparable time), since only the loss function changes, not the architecture/size.\n",
    "\n",
    "Conclusion: a moderate amount of Label Smoothing (e.g., 0.5–0.7) is optimal for this task and settings. No smoothing (0.0) and very high smoothing (0.9) are suboptimal.\n"
   ],
   "id": "bfb876897d5eda31"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Criteria checklist\n",
    "\n",
    "- [x] Baseline model trained with default parameters (baseline run with `smoothing=0.1`, time and BLEU recorded)\n",
    "- [x] Multiple versions trained with different Label Smoothing values (`0.0, 0.5, 0.7, 0.9`)\n",
    "- [x] Results analyzed (see “Analysis of Label Smoothing effect”)\n"
   ],
   "id": "74fc483f3798be8d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
