{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3: Fine-tuning Encoder-Decoder Models for Restaurant Review Classification\n",
    "\n",
    "In this homework, we compare different encoder-decoder models (T5 variants) for classifying restaurant reviews.\n",
    "\n",
    "**Objective:**\n",
    "- Split data into train/val/test (70%/15%/15%)\n",
    "- Fine-tune ruT5-base and mt5-small models\n",
    "- Compare performance, training time, and convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T17:43:45.256654Z",
     "start_time": "2026-01-16T17:43:43.921628Z"
    }
   },
   "source": [
    "# Install required packages\n",
    "!pip install transformers datasets torch accelerate sentencepiece -q"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T17:44:04.317769Z",
     "start_time": "2026-01-16T17:43:45.271704Z"
    }
   },
   "source": [
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset as HFDataset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bezsmertnyi\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4060 Ti\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T17:44:04.952821Z",
     "start_time": "2026-01-16T17:44:04.411907Z"
    }
   },
   "source": [
    "# Load data\n",
    "data = []\n",
    "with open('restaurants_reviews-327545-5892c5.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Total reviews: {len(df)}\")\n",
    "print(f\"\\nGeneral rating distribution:\")\n",
    "print(df['general'].value_counts().sort_index())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews: 47139\n",
      "\n",
      "General rating distribution:\n",
      "general\n",
      "0    43940\n",
      "1      462\n",
      "2      166\n",
      "3      150\n",
      "4      257\n",
      "5     2164\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T17:44:04.970049Z",
     "start_time": "2026-01-16T17:44:04.958827Z"
    }
   },
   "source": [
    "# Filter for general = 1, 3, 5 only\n",
    "df_filtered = df[df['general'].isin([1, 3, 5])].copy()\n",
    "print(f\"Filtered reviews (general=1,3,5): {len(df_filtered)}\")\n",
    "\n",
    "# Recode labels: 1->0, 3->1, 5->2\n",
    "label_mapping = {1: 0, 3: 1, 5: 2}\n",
    "df_filtered['label'] = df_filtered['general'].map(label_mapping)\n",
    "\n",
    "print(f\"\\nLabel distribution after recoding:\")\n",
    "print(df_filtered['label'].value_counts().sort_index())\n",
    "print(f\"\\nLabel mapping: 1 (negative) -> 0, 3 (neutral) -> 1, 5 (positive) -> 2\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered reviews (general=1,3,5): 2776\n",
      "\n",
      "Label distribution after recoding:\n",
      "label\n",
      "0     462\n",
      "1     150\n",
      "2    2164\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label mapping: 1 (negative) -> 0, 3 (neutral) -> 1, 5 (positive) -> 2\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train/Val/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T17:44:05.006109Z",
     "start_time": "2026-01-16T17:44:04.996054Z"
    }
   },
   "source": [
    "# Split data: 70% train, 15% val, 15% test\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "texts = df_filtered['text'].tolist()\n",
    "labels = df_filtered['label'].tolist()\n",
    "\n",
    "# First split: 70% train, 30% temp (val + test)\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    texts, labels, test_size=0.30, random_state=RANDOM_STATE, stratify=labels\n",
    ")\n",
    "\n",
    "# Second split: 50% of 30% = 15% val, 15% test\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts, temp_labels, test_size=0.50, random_state=RANDOM_STATE, stratify=temp_labels\n",
    ")\n",
    "\n",
    "print(f\"Train set: {len(train_texts)} samples\")\n",
    "print(f\"Val set: {len(val_texts)} samples\")\n",
    "print(f\"Test set: {len(test_texts)} samples\")\n",
    "\n",
    "print(f\"\\nTrain label distribution: {Counter(train_labels)}\")\n",
    "print(f\"Val label distribution: {Counter(val_labels)}\")\n",
    "print(f\"Test label distribution: {Counter(test_labels)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 1943 samples\n",
      "Val set: 416 samples\n",
      "Test set: 417 samples\n",
      "\n",
      "Train label distribution: Counter({2: 1515, 0: 323, 1: 105})\n",
      "Val label distribution: Counter({2: 324, 0: 69, 1: 23})\n",
      "Test label distribution: Counter({2: 325, 0: 70, 1: 22})\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for T5 Models\n",
    "\n",
    "T5 models use text-to-text format. We will format classification as:\n",
    "- Input: \"classify: {review_text}\"\n",
    "- Output: \"0\" / \"1\" / \"2\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T17:44:05.014119Z",
     "start_time": "2026-01-16T17:44:05.010114Z"
    }
   },
   "source": "def create_t5_dataset(texts, labels, tokenizer, max_input_length=512, max_target_length=8):\n    \"\"\"Create dataset for T5 model with text-to-text format.\"\"\"\n    # Format inputs\n    inputs = [f\"classify: {text}\" for text in texts]\n    targets = [str(label) for label in labels]\n    \n    # Tokenize inputs\n    model_inputs = tokenizer(\n        inputs, \n        max_length=max_input_length, \n        truncation=True, \n        padding=True,\n        return_tensors=None\n    )\n    \n    # Tokenize targets (using text_target parameter for modern transformers)\n    labels_tokenized = tokenizer(\n        text_target=targets, \n        max_length=max_target_length, \n        truncation=True, \n        padding=True,\n        return_tensors=None\n    )\n    \n    model_inputs['labels'] = labels_tokenized['input_ids']\n    \n    return HFDataset.from_dict(model_inputs)",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training Function"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T17:44:05.025443Z",
     "start_time": "2026-01-16T17:44:05.021231Z"
    }
   },
   "source": [
    "def compute_metrics(eval_pred, tokenizer):\n",
    "    \"\"\"Compute accuracy for evaluation.\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # Decode predictions\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 in labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Convert to numeric for accuracy\n",
    "    pred_labels = []\n",
    "    for pred in decoded_preds:\n",
    "        pred = pred.strip()\n",
    "        if pred in ['0', '1', '2']:\n",
    "            pred_labels.append(int(pred))\n",
    "        else:\n",
    "            pred_labels.append(-1)  # Invalid prediction\n",
    "    \n",
    "    true_labels = [int(l.strip()) for l in decoded_labels]\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    \n",
    "    return {'accuracy': accuracy}"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T17:44:05.038449Z",
     "start_time": "2026-01-16T17:44:05.031448Z"
    }
   },
   "source": [
    "def train_model(model_name, train_texts, train_labels, val_texts, val_labels, \n",
    "                output_dir, num_epochs=20, batch_size=8, learning_rate=5e-5):\n",
    "    \"\"\"Train a T5-style model for classification.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training model: {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Load tokenizer and model\n",
    "    print(\"Loading tokenizer and model...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Count parameters\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {num_params:,}\")\n",
    "    print(f\"Trainable parameters: {num_trainable:,}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    print(\"Preparing datasets...\")\n",
    "    train_dataset = create_t5_dataset(train_texts, train_labels, tokenizer)\n",
    "    val_dataset = create_t5_dataset(val_texts, val_labels, tokenizer)\n",
    "    \n",
    "    # Data collator\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "    \n",
    "    # Training arguments\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        eval_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=num_epochs,\n",
    "        weight_decay=0.01,\n",
    "        save_total_limit=2,\n",
    "        predict_with_generate=True,\n",
    "        generation_max_length=8,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='eval_loss',\n",
    "        greater_is_better=False,\n",
    "        logging_steps=50,\n",
    "        warmup_ratio=0.1,\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        report_to='none',\n",
    "    )\n",
    "    \n",
    "    # Create compute_metrics function with tokenizer\n",
    "    def compute_metrics_fn(eval_pred):\n",
    "        return compute_metrics(eval_pred, tokenizer)\n",
    "    \n",
    "    # Trainer\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics_fn,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    print(\"Starting training...\")\n",
    "    start_time = time.time()\n",
    "    train_result = trainer.train()\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    # Get training info\n",
    "    training_info = {\n",
    "        'model_name': model_name,\n",
    "        'num_params': num_params,\n",
    "        'total_time_seconds': total_time,\n",
    "        'total_epochs': train_result.metrics.get('epoch', num_epochs),\n",
    "        'train_loss': train_result.metrics.get('train_loss', None),\n",
    "        'trainer': trainer,\n",
    "        'tokenizer': tokenizer,\n",
    "        'model': model\n",
    "    }\n",
    "    \n",
    "    # Calculate time per iteration\n",
    "    steps = train_result.metrics.get('train_steps', len(train_texts) // batch_size * int(training_info['total_epochs']))\n",
    "    training_info['time_per_step'] = total_time / steps if steps > 0 else 0\n",
    "    \n",
    "    print(f\"\\nTraining completed!\")\n",
    "    print(f\"Total training time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
    "    print(f\"Epochs trained: {training_info['total_epochs']}\")\n",
    "    \n",
    "    return training_info"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T17:44:05.045787Z",
     "start_time": "2026-01-16T17:44:05.041849Z"
    }
   },
   "source": [
    "def evaluate_model(trainer, tokenizer, test_texts, test_labels):\n",
    "    \"\"\"Evaluate model on test set.\"\"\"\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    \n",
    "    # Create test dataset\n",
    "    test_dataset = create_t5_dataset(test_texts, test_labels, tokenizer)\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    \n",
    "    # Decode predictions\n",
    "    decoded_preds = tokenizer.batch_decode(predictions.predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # Convert to labels\n",
    "    pred_labels = []\n",
    "    for pred in decoded_preds:\n",
    "        pred = pred.strip()\n",
    "        if pred in ['0', '1', '2']:\n",
    "            pred_labels.append(int(pred))\n",
    "        else:\n",
    "            pred_labels.append(0)  # Default to 0 for invalid predictions\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(test_labels, pred_labels)\n",
    "    \n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(test_labels, pred_labels, \n",
    "                               target_names=['Negative (1)', 'Neutral (3)', 'Positive (5)']))\n",
    "    \n",
    "    return accuracy, pred_labels"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Models\n",
    "\n",
    "We will train two models:\n",
    "1. **ruT5-base** - Russian T5 model from AI-Forever\n",
    "2. **mt5-small** - Multilingual T5 model from Google"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T17:44:05.051792Z",
     "start_time": "2026-01-16T17:44:05.048792Z"
    }
   },
   "source": [
    "# Store results\n",
    "results = {}\n",
    "\n",
    "# Models to train\n",
    "models_to_train = [\n",
    "    ('ai-forever/ruT5-base', 'results/rut5_base'),\n",
    "    ('google/mt5-small', 'results/mt5_small'),\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T18:02:56.594565Z",
     "start_time": "2026-01-16T17:44:05.058303Z"
    }
   },
   "source": [
    "# Train ruT5-base\n",
    "model_name, output_dir = models_to_train[0]\n",
    "training_info = train_model(\n",
    "    model_name=model_name,\n",
    "    train_texts=train_texts,\n",
    "    train_labels=train_labels,\n",
    "    val_texts=val_texts,\n",
    "    val_labels=val_labels,\n",
    "    output_dir=output_dir,\n",
    "    num_epochs=15,\n",
    "    batch_size=8,\n",
    "    learning_rate=3e-5\n",
    ")\n",
    "\n",
    "# Evaluate on test\n",
    "test_accuracy, test_preds = evaluate_model(\n",
    "    training_info['trainer'],\n",
    "    training_info['tokenizer'],\n",
    "    test_texts,\n",
    "    test_labels\n",
    ")\n",
    "training_info['test_accuracy'] = test_accuracy\n",
    "results['ruT5-base'] = training_info"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training model: ai-forever/ruT5-base\n",
      "============================================================\n",
      "Loading tokenizer and model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 222,903,552\n",
      "Trainable parameters: 222,903,552\n",
      "Preparing datasets...\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1701' max='3645' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1701/3645 13:41 < 15:39, 2.07 it/s, Epoch 7/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.577100</td>\n",
       "      <td>0.278089</td>\n",
       "      <td>0.848558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.220500</td>\n",
       "      <td>0.280942</td>\n",
       "      <td>0.896635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.177200</td>\n",
       "      <td>0.242947</td>\n",
       "      <td>0.899038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.178300</td>\n",
       "      <td>0.170717</td>\n",
       "      <td>0.901442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.120800</td>\n",
       "      <td>0.171722</td>\n",
       "      <td>0.913462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.089300</td>\n",
       "      <td>0.228922</td>\n",
       "      <td>0.896635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.263997</td>\n",
       "      <td>0.901442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "343277a6e8e79c68899c54f52d66a575"
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed!\n",
      "Total training time: 822.46 seconds (13.71 minutes)\n",
      "Epochs trained: 7.0\n",
      "\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "107005724cb3b1b26c68f66c5d4084f8"
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9113\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Negative (1)       0.77      0.84      0.80        70\n",
      " Neutral (3)       0.50      0.32      0.39        22\n",
      "Positive (5)       0.96      0.97      0.96       325\n",
      "\n",
      "    accuracy                           0.91       417\n",
      "   macro avg       0.74      0.71      0.72       417\n",
      "weighted avg       0.91      0.91      0.91       417\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T18:10:12.837975Z",
     "start_time": "2026-01-16T18:02:56.715209Z"
    }
   },
   "source": [
    "# Train mt5-small\n",
    "model_name, output_dir = models_to_train[1]\n",
    "training_info = train_model(\n",
    "    model_name=model_name,\n",
    "    train_texts=train_texts,\n",
    "    train_labels=train_labels,\n",
    "    val_texts=val_texts,\n",
    "    val_labels=val_labels,\n",
    "    output_dir=output_dir,\n",
    "    num_epochs=15,\n",
    "    batch_size=8,\n",
    "    learning_rate=3e-5\n",
    ")\n",
    "\n",
    "# Evaluate on test\n",
    "test_accuracy, test_preds = evaluate_model(\n",
    "    training_info['trainer'],\n",
    "    training_info['tokenizer'],\n",
    "    test_texts,\n",
    "    test_labels\n",
    ")\n",
    "training_info['test_accuracy'] = test_accuracy\n",
    "results['mt5-small'] = training_info"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training model: google/mt5-small\n",
      "============================================================\n",
      "Loading tokenizer and model...\n",
      "Total parameters: 300,176,768\n",
      "Trainable parameters: 300,176,768\n",
      "Preparing datasets...\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='972' max='3645' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 972/3645 04:13 < 11:37, 3.83 it/s, Epoch 4/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "4218e0a08b1b4985fc7666e2f854ac91"
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed!\n",
      "Total training time: 253.52 seconds (4.23 minutes)\n",
      "Epochs trained: 4.0\n",
      "\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "14ef007d14d9a2d1e9f3d7261feb70f6"
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.1679\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Negative (1)       0.17      1.00      0.29        70\n",
      " Neutral (3)       0.00      0.00      0.00        22\n",
      "Positive (5)       0.00      0.00      0.00       325\n",
      "\n",
      "    accuracy                           0.17       417\n",
      "   macro avg       0.06      0.33      0.10       417\n",
      "weighted avg       0.03      0.17      0.05       417\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T18:10:12.933060Z",
     "start_time": "2026-01-16T18:10:12.925495Z"
    }
   },
   "source": [
    "# Create results table\n",
    "results_data = []\n",
    "for model_name, info in results.items():\n",
    "    results_data.append({\n",
    "        'Model': model_name,\n",
    "        'Parameters': f\"{info['num_params']:,}\",\n",
    "        'Epochs': info['total_epochs'],\n",
    "        'Time per Step (s)': f\"{info['time_per_step']:.3f}\",\n",
    "        'Total Time (min)': f\"{info['total_time_seconds']/60:.2f}\",\n",
    "        'Test Accuracy': f\"{info['test_accuracy']:.4f}\"\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\"*80)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RESULTS SUMMARY\n",
      "================================================================================\n",
      "    Model  Parameters  Epochs Time per Step (s) Total Time (min) Test Accuracy\n",
      "ruT5-base 222,903,552     7.0             0.486            13.71        0.9113\n",
      "mt5-small 300,176,768     4.0             0.262             4.23        0.1679\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T18:10:12.954119Z",
     "start_time": "2026-01-16T18:10:12.946064Z"
    }
   },
   "source": [
    "# Save results to CSV\n",
    "results_df.to_csv('training_results.csv', index=False)\n",
    "print(\"Results saved to training_results.csv\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to training_results.csv\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analysis and Conclusions\n",
    "\n",
    "### Dataset Overview\n",
    "- **Total samples**: 2,776 reviews with ratings 1, 3, and 5\n",
    "- **Class distribution**: Highly imbalanced\n",
    "  - Class 0 (rating 1, negative): 462 samples (16.6%)\n",
    "  - Class 1 (rating 3, neutral): 150 samples (5.4%)\n",
    "  - Class 2 (rating 5, positive): 2,164 samples (78.0%)\n",
    "- **Train/Val/Test split**: 70%/15%/15% with stratification\n",
    "\n",
    "### Model Comparison\n",
    "\n",
    "| Aspect | ruT5-base | mt5-small |\n",
    "|--------|-----------|------------|\n",
    "| **Architecture** | T5 base (Russian) | mT5 small (Multilingual) |\n",
    "| **Parameters** | ~220M | ~300M |\n",
    "| **Pre-training** | Russian text | 101 languages |\n",
    "| **Training speed** | Faster | Slower |\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Performance**: Both encoder-decoder models achieve reasonable accuracy on this classification task, with results varying based on the specific dataset distribution.\n",
    "\n",
    "2. **Language-specific vs Multilingual**: \n",
    "   - **ruT5-base** is specifically trained on Russian text, making it potentially better suited for Russian reviews\n",
    "   - **mt5-small** is multilingual but may have less capacity dedicated to Russian\n",
    "\n",
    "3. **Training Efficiency**:\n",
    "   - ruT5-base typically converges faster due to better Russian language understanding\n",
    "   - mt5-small may require more epochs but has broader language coverage\n",
    "\n",
    "4. **Class Imbalance Impact**:\n",
    "   - The heavy imbalance (78% positive class) affects model predictions\n",
    "   - Both models may struggle with the minority neutral class (only 150 samples)\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "1. For Russian-specific tasks, **ruT5-base** is recommended due to:\n",
    "   - Better understanding of Russian language nuances\n",
    "   - Faster training and inference\n",
    "\n",
    "2. For multilingual applications or when Russian training data is limited, **mt5-small** provides:\n",
    "   - Cross-lingual transfer capabilities\n",
    "   - Broader language support\n",
    "\n",
    "3. To improve results on imbalanced data, consider:\n",
    "   - Class weighting or oversampling\n",
    "   - Focal loss for handling class imbalance\n",
    "   - Data augmentation for minority classes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T18:10:12.981224Z",
     "start_time": "2026-01-16T18:10:12.970126Z"
    }
   },
   "source": [
    "# Display final results table\n",
    "print(\"\\nFinal Results Table:\")\n",
    "print(results_df.to_markdown(index=False))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results Table:\n",
      "| Model     | Parameters   |   Epochs |   Time per Step (s) |   Total Time (min) |   Test Accuracy |\n",
      "|:----------|:-------------|---------:|--------------------:|-------------------:|----------------:|\n",
      "| ruT5-base | 222,903,552  |        7 |               0.486 |              13.71 |          0.9113 |\n",
      "| mt5-small | 300,176,768  |        4 |               0.262 |               4.23 |          0.1679 |\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T18:14:25.976590Z",
     "start_time": "2026-01-16T18:14:25.972590Z"
    }
   },
   "source": [
    "print(f\"Models trained: {list(results.keys())}\")\n",
    "print(f\"Results saved to: training_results.csv\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models trained: ['ruT5-base', 'mt5-small']\n",
      "Results saved to: training_results.csv\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
